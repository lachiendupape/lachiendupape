version: "3.9"

services:
  # --- OpenAI-compatible endpoint (fast, great for agents/SDKs) ---
  vllm:
    image: vllm/vllm-openai:latest
    container_name: vllm
    restart: unless-stopped
    ports:
      - "8000:8000"   # OpenAI-compatible /v1 endpoint
    environment:
      - HF_TOKEN=${HF_TOKEN-}     # optional, for gated models
    deploy:
      resources:
        reservations:
          devices:
            - capabilities: ["gpu"]
    gpus: all
    command: >
      --model meta-llama/Llama-3.1-8B-Instruct
      --quantization awq
      --max-model-len 8192
    # If you prefer to stick to Ollama only, you can omit this service.

  # --- Vector database for RAG ---
  qdrant:
    image: qdrant/qdrant:latest
    container_name: qdrant
    restart: unless-stopped
    ports:
      - "6333:6333"   # REST
      - "6334:6334"   # gRPC
    volumes:
      - ./qdrant_data:/qdrant/storage
